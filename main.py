import os
import argparse
import numpy as np
from config import *
from utils.reproducibility import set_reproducibility
from utils.model_utils import create_model_directories
from src.environment.environment import Environment
from src.data.job_manager import JobManager
from src.schedulers.first_fit import FirstFitScheduler
from src.schedulers.random_fit import RandomFitScheduler
from src.training.trainer import Trainer
from src.evaluation.visualization import plot_batch_power_consumption


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description='é›²ç«¯ä»»å‹™èª¿åº¦å¼·åŒ–å­¸ç¿’æ¯”è¼ƒå¯¦é©—',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ç’°å¢ƒé…ç½®åƒæ•¸
    env_group = parser.add_argument_group('ç’°å¢ƒé…ç½®')
    env_group.add_argument('--servers', type=int, default=500,
                          help='ç¸½æœå‹™å™¨æ•¸é‡')
    env_group.add_argument('--dc-size', type=int, default=50,
                          help='æ¯å€‹è³‡æ–™ä¸­å¿ƒçš„æœå‹™å™¨æ•¸é‡')
    env_group.add_argument('--ac-per-server', type=int, default=2,
                          help='æ¯å€‹æœå‹™å™¨çš„æ‡‰ç”¨å®¹å™¨æ•¸é‡')
    
    # è¨“ç·´åƒæ•¸
    train_group = parser.add_argument_group('è¨“ç·´é…ç½®')
    train_group.add_argument('--episodes', type=int, default=100,
                           help='è¨“ç·´episodeæ•¸é‡')
    train_group.add_argument('--jobs', type=int, default=100,
                           help='æ¯å€‹episodeçš„jobæ•¸é‡')
    train_group.add_argument('--seed', type=int, default=42,
                           help='éš¨æ©Ÿç¨®å­')
    
    # æ•¸æ“šå’Œè¼¸å‡ºé…ç½®
    data_group = parser.add_argument_group('æ•¸æ“šå’Œè¼¸å‡º')
    data_group.add_argument('--csv', type=str, default=None,
                          help='CSVæ•¸æ“šæ–‡ä»¶è·¯å¾‘')
    data_group.add_argument('--output-dir', type=str, default='./results',
                          help='çµæœè¼¸å‡ºç›®éŒ„')
    data_group.add_argument('--models-dir', type=str, default='./models',
                          help='æ¨¡å‹ä¿å­˜ç›®éŒ„')
    
    # æ–¹æ³•é¸æ“‡
    method_group = parser.add_argument_group('æ–¹æ³•é¸æ“‡')
    method_group.add_argument('--methods', nargs='+', 
                            default=['MDPT4JS-HA', 'MDPT4JS', 'ACT4JS', 'AC', 'DQN', 'First Fit', 'Random Fit'],
                            choices=['MDPT4JS-HA', 'MDPT4JS', 'ACT4JS', 'AC', 'DQN', 'First Fit', 'Random Fit'],
                            help='è¦åŸ·è¡Œçš„æ–¹æ³•åˆ—è¡¨')
    method_group.add_argument('--exclude', nargs='+', default=[],
                            choices=['MDPT4JS-HA', 'MDPT4JS', 'ACT4JS', 'AC', 'DQN', 'First Fit', 'Random Fit'],
                            help='è¦æ’é™¤çš„æ–¹æ³•åˆ—è¡¨')
    
    # å…¶ä»–é¸é …
    other_group = parser.add_argument_group('å…¶ä»–é¸é …')
    other_group.add_argument('--verbose', action='store_true',
                           help='é¡¯ç¤ºè©³ç´°è¨“ç·´ä¿¡æ¯')
    other_group.add_argument('--no-save', action='store_true',
                           help='ä¸ä¿å­˜æ¨¡å‹å’Œçµæœ')
    other_group.add_argument('--dry-run', action='store_true',
                           help='åªé¡¯ç¤ºé…ç½®ä¿¡æ¯ï¼Œä¸åŸ·è¡Œè¨“ç·´')
    
    return parser.parse_args()


def validate_arguments(args):
    """é©—è­‰å‘½ä»¤è¡Œåƒæ•¸çš„åˆç†æ€§"""
    errors = []
    
    # é©—è­‰ç’°å¢ƒåƒæ•¸
    if args.servers <= 0:
        errors.append("æœå‹™å™¨æ•¸é‡å¿…é ˆå¤§æ–¼0")
    
    if args.dc_size <= 0:
        errors.append("æ¯å€‹è³‡æ–™ä¸­å¿ƒçš„æœå‹™å™¨æ•¸é‡å¿…é ˆå¤§æ–¼0")
    
    if args.servers % args.dc_size != 0:
        errors.append(f"ç¸½æœå‹™å™¨æ•¸({args.servers})å¿…é ˆèƒ½è¢«è³‡æ–™ä¸­å¿ƒå¤§å°({args.dc_size})æ•´é™¤")
    
    if args.ac_per_server <= 0:
        errors.append("æ¯å€‹æœå‹™å™¨çš„å®¹å™¨æ•¸é‡å¿…é ˆå¤§æ–¼0")
    
    # é©—è­‰è¨“ç·´åƒæ•¸
    if args.episodes <= 0:
        errors.append("Episodeæ•¸é‡å¿…é ˆå¤§æ–¼0")
    
    if args.jobs <= 0:
        errors.append("æ¯å€‹episodeçš„jobæ•¸é‡å¿…é ˆå¤§æ–¼0")
    
    # é©—è­‰CSVæ–‡ä»¶
    if args.csv and not os.path.exists(args.csv):
        errors.append(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv}")
    
    # è™•ç†æ–¹æ³•æ’é™¤
    selected_methods = [m for m in args.methods if m not in args.exclude]
    if not selected_methods:
        errors.append("è‡³å°‘éœ€è¦é¸æ“‡ä¸€å€‹æ–¹æ³•åŸ·è¡Œ")
    
    if errors:
        print(" åƒæ•¸é©—è­‰å¤±æ•—:")
        for error in errors:
            print(f"   - {error}")
        return False, []
    
    return True, selected_methods


def display_configuration(args, selected_methods):
    """é¡¯ç¤ºå¯¦é©—é…ç½®ä¿¡æ¯"""
    num_dcs = args.servers // args.dc_size
    total_acs = args.servers * args.ac_per_server
    
    print(" å¯¦é©—é…ç½®ä¿¡æ¯")
    print("=" * 60)
    print(f"  ç’°å¢ƒé…ç½®:")
    print(f"   â”œâ”€ ç¸½æœå‹™å™¨æ•¸é‡: {args.servers}")
    print(f"   â”œâ”€ è³‡æ–™ä¸­å¿ƒæ•¸é‡: {num_dcs}")
    print(f"   â”œâ”€ æ¯å€‹DCæœå‹™å™¨æ•¸: {args.dc_size}")
    print(f"   â”œâ”€ æ¯æœå‹™å™¨å®¹å™¨æ•¸: {args.ac_per_server}")
    print(f"   â””â”€ ç¸½å®¹å™¨æ•¸é‡: {total_acs}")
    
    print(f"\n è¨“ç·´é…ç½®:")
    print(f"   â”œâ”€ è¨“ç·´Episodes: {args.episodes}")
    print(f"   â”œâ”€ æ¯Episode Jobs: {args.jobs}")
    print(f"   â””â”€ éš¨æ©Ÿç¨®å­: {args.seed}")
    
    print(f"\n è·¯å¾‘é…ç½®:")
    print(f"   â”œâ”€ çµæœç›®éŒ„: {args.output_dir}")
    print(f"   â”œâ”€ æ¨¡å‹ç›®éŒ„: {args.models_dir}")
    print(f"   â””â”€ CSVæ–‡ä»¶: {args.csv or 'ä½¿ç”¨éš¨æ©Ÿç”Ÿæˆæ•¸æ“š'}")
    
    print(f"\n åŸ·è¡Œæ–¹æ³• ({len(selected_methods)}å€‹):")
    for i, method in enumerate(selected_methods, 1):
        print(f"   {i}. {method}")
    
    if args.exclude:
        print(f"\n æ’é™¤æ–¹æ³•: {', '.join(args.exclude)}")
    
    print("=" * 60)


def update_configs(args):
    """æ ¹æ“šå‘½ä»¤è¡Œåƒæ•¸æ›´æ–°é…ç½®"""
    global ENV_CONFIG, TRAINING_CONFIG, PATHS
    
    # æ›´æ–°ç’°å¢ƒé…ç½®
    ENV_CONFIG.update({
        'total_servers': args.servers,
        'dc_size': args.dc_size,
        'ac_per_server': args.ac_per_server,
    })
    
    # æ›´æ–°è¨“ç·´é…ç½®
    TRAINING_CONFIG.update({
        'num_episodes': args.episodes,
        'jobs_per_episode': args.jobs,
        'random_seed': args.seed,
    })
    
    # æ›´æ–°è·¯å¾‘é…ç½®
    PATHS.update({
        'save_path': args.models_dir,
        'results_path': args.output_dir,
        'logs_path': os.path.join(args.output_dir, 'logs'),
        'plots_path': os.path.join(args.output_dir, 'plots'),
    })


def main():
    """ä¸»ç¨‹å¼å‡½æ•¸"""
    # è§£æå‘½ä»¤è¡Œåƒæ•¸
    args = parse_arguments()
    
    # é©—è­‰åƒæ•¸
    valid, selected_methods = validate_arguments(args)
    if not valid:
        return 1
    
    # é¡¯ç¤ºé…ç½®
    display_configuration(args, selected_methods)
    
    # å¦‚æœæ˜¯dry runï¼Œåªé¡¯ç¤ºé…ç½®å¾Œé€€å‡º
    if args.dry_run:
        print("\n Dry run æ¨¡å¼ - åƒ…é¡¯ç¤ºé…ç½®ä¿¡æ¯ï¼Œä¸åŸ·è¡Œè¨“ç·´")
        return 0
    
    # æ›´æ–°å…¨å±€é…ç½®
    update_configs(args)
    
    print("\n" + "=" * 60)
    print(" é–‹å§‹åŸ·è¡Œé›²ç«¯ä»»å‹™èª¿åº¦å¼·åŒ–å­¸ç¿’æ¯”è¼ƒå¯¦é©—")
    print("=" * 60)
    
    # è¨­ç½®éš¨æ©Ÿç¨®å­ç¢ºä¿å¯å¾©ç¾æ€§
    set_reproducibility(TRAINING_CONFIG['random_seed'])
    
    # å‰µå»ºå¿…è¦çš„ç›®éŒ„
    for path in PATHS.values():
        if not os.path.exists(path):
            os.makedirs(path)
            print(f" å‰µå»ºç›®éŒ„: {path}")
    
    # å»ºç«‹ä½œæ¥­ç®¡ç†å™¨ä¸¦åŠ è¼‰CSVæ•¸æ“š
    job_manager = JobManager()
    csv_file_path = args.csv
    
    if csv_file_path:
        print(f"\n è¼‰å…¥CSVæ•¸æ“š: {csv_file_path}")
        if job_manager.load_all_jobs_from_csv(csv_file_path):
            print(" CSVæ•¸æ“šè¼‰å…¥æˆåŠŸ")
        else:
            print(" CSVæ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨éš¨æ©Ÿç”Ÿæˆæ•¸æ“š")
            csv_file_path = None
    else:
        print("ä½¿ç”¨éš¨æ©Ÿç”Ÿæˆæ•¸æ“š")
    
    # å‰µå»ºç’°å¢ƒé…ç½®
    env_config = ENV_CONFIG.copy()
    training_config = TRAINING_CONFIG.copy()
    
    # å»ºç«‹å¤šå€‹ç¨ç«‹ç’°å¢ƒï¼ˆé¿å…å„æ–¹æ³•ä¹‹é–“äº’ç›¸å¹²æ“¾ï¼‰
    print(f"\n  å‰µå»º{len(selected_methods)}å€‹ç¨ç«‹ç’°å¢ƒ...")
    environments = {}
    
    for method in selected_methods:
        environments[method] = Environment(
            total_servers=env_config['total_servers'],
            dc_size=env_config['dc_size'],
            ac_per_server=env_config['ac_per_server']
        )
        print(f"    {method} ç’°å¢ƒå·²å‰µå»º")
    
    # å‰µå»ºæ¨¡å‹ä¿å­˜ç›®éŒ„
    if not args.no_save:
        create_model_directories(PATHS['save_path'], selected_methods)
    
    # å­˜å„²æ‰€æœ‰æ–¹æ³•çš„çµæœ
    all_results = {}
    
    print("\n" + "=" * 60)
    print(" é–‹å§‹åŸ·è¡Œå¯¦é©—")
    print("=" * 60)
    
    # 1. åŸ·è¡Œå¼·åŒ–å­¸ç¿’æ–¹æ³•
    rl_methods = [m for m in selected_methods if m not in ['First Fit', 'Random Fit']]
    
    if rl_methods:
        print(f"\n åŸ·è¡Œå¼·åŒ–å­¸ç¿’æ–¹æ³• ({len(rl_methods)}å€‹)")
        print("-" * 40)
        
        trainer = Trainer()
        
        for i, method in enumerate(rl_methods, 1):
            print(f"\n[{i}/{len(rl_methods)}]  åŸ·è¡Œ {method} æ–¹æ³•è¨“ç·´...")
            
            rewards, losses, agents = trainer.train_method(
                env=environments[method],
                method=method,
                num_episodes=training_config['num_episodes'],
                jobs_per_episode=training_config['jobs_per_episode'],
                save_path=PATHS['save_path'] if not args.no_save else None,
                csv_file_path=csv_file_path,
                job_manager=job_manager,
                verbose=args.verbose
            )
            
            all_results[method] = {
                'rewards': rewards,
                'losses': losses,
                'agents': agents,
                'env': environments[method]
            }
            
            print(f" {method} è¨“ç·´å®Œæˆ")
    
    # 2. åŸ·è¡ŒåŸºæº–æ–¹æ³•
    baseline_methods = [m for m in selected_methods if m in ['First Fit', 'Random Fit']]
    
    if baseline_methods:
        print(f"\n åŸ·è¡ŒåŸºæº–èª¿åº¦æ–¹æ³• ({len(baseline_methods)}å€‹)")
        print("-" * 40)
        
        for i, method in enumerate(baseline_methods, 1):
            print(f"\n[{i}/{len(baseline_methods)}]  åŸ·è¡Œ {method} æ–¹æ³•...")
            
            if method == 'First Fit':
                scheduler = FirstFitScheduler(environments[method])
            else:  # Random Fit
                scheduler = RandomFitScheduler(environments[method])
            
            rewards, power = scheduler.run_multiple_episodes(
                num_episodes=training_config['num_episodes'],
                jobs_per_episode=training_config['jobs_per_episode'],
                csv_file_path=csv_file_path,
                job_manager=job_manager
            )
            
            all_results[method] = {
                'rewards': rewards,
                'power': power,
                'env': environments[method]
            }
            
            print(f" {method} åŸ·è¡Œå®Œæˆ")
    
    # 3. ä¿å­˜å¯¦é©—çµæœ
    if not args.no_save:
        print(f"\n ä¿å­˜å¯¦é©—çµæœåˆ° {PATHS['results_path']}")
        print("-" * 40)
        
        # ä¿å­˜æ•¸å€¼æ•¸æ“š
        for method, result in all_results.items():
            method_safe = method.lower().replace(" ", "_").replace("-", "_")
            
            # ä¿å­˜çå‹µæ•¸æ“š
            np.save(f'{PATHS["results_path"]}/rewards_{method_safe}.npy', 
                    np.array(result['rewards']))
            
            # ä¿å­˜èƒ½è€—æ•¸æ“š
            if 'power' in result:
                np.save(f'{PATHS["results_path"]}/power_{method_safe}.npy', 
                        np.array(result['power']))
            
            # ä¿å­˜æå¤±æ•¸æ“š
            if 'losses' in result:
                np.save(f'{PATHS["results_path"]}/losses_{method_safe}.npy', 
                        np.array(result['losses']))
            
            # ä¿å­˜æ‰¹æ¬¡èƒ½è€—æ•¸æ“š
            if result['env'].batch_power_records:
                batch_power_data = np.array([sum(batch) for batch in result['env'].batch_power_records])
                np.save(f'{PATHS["results_path"]}/batch_power_{method_safe}.npy', batch_power_data)
            
            print(f"    {method} æ•¸æ“šå·²ä¿å­˜")
        
        # 4. ç”Ÿæˆå¯è¦–åŒ–çµæœ
        print(f"\n ç”Ÿæˆå¯è¦–åŒ–åœ–è¡¨...")
        
        # å‰µå»ºç’°å¢ƒå­—å…¸ç”¨æ–¼å¯è¦–åŒ–
        envs_for_plot = {method: result['env'] for method, result in all_results.items()}
        
        # ç¹ªè£½æ‰¹æ¬¡èƒ½è€—æ¯”è¼ƒåœ–
        plot_batch_power_consumption(envs_for_plot, selected_methods, PATHS['plots_path'])
        print(f"  åœ–è¡¨å·²ä¿å­˜åˆ° {PATHS['plots_path']}")
    
    # 5. é¡¯ç¤ºå¯¦é©—ç¸½çµ
    print("\n" + "=" * 60)
    print(" å¯¦é©—ç¸½çµ")
    print("=" * 60)
    
    # é¡¯ç¤ºç³»çµ±é…ç½®ç¸½çµ
    num_dcs = env_config['total_servers'] // env_config['dc_size']
    total_acs = env_config['total_servers'] * env_config['ac_per_server']
    print(f"  ç³»çµ±é…ç½®: {num_dcs}å€‹DC, {env_config['total_servers']}å°æœå‹™å™¨, {total_acs}å€‹å®¹å™¨")
    print(f" å¯¦é©—è¦æ¨¡: {training_config['num_episodes']}å€‹Episodes, æ¯å€‹{training_config['jobs_per_episode']}å€‹Jobs")
    
    # é¡¯ç¤ºå„æ–¹æ³•çš„å¹³å‡èƒ½è€—æ¯”è¼ƒï¼ˆæŒ‰åŸ·è¡Œé †åºï¼‰
    print(f"\nğŸ’¡ å„æ–¹æ³•æ¯æ‰¹æ¬¡(100å€‹Job)å¹³å‡èƒ½è€—æ¯”è¼ƒ:")
    for method in selected_methods:
        if method in all_results:
            env = all_results[method]['env']
            if env.batch_power_records:
                avg_power = np.mean([sum(batch) for batch in env.batch_power_records])
                print(f"   {method:15}: {avg_power:8.2f}")
    
    # é¡¯ç¤ºä»»å‹™æˆåŠŸç‡æ¯”è¼ƒï¼ˆæŒ‰åŸ·è¡Œé †åºï¼‰
    print(f"\n å„æ–¹æ³•ä»»å‹™æˆåŠŸç‡æ¯”è¼ƒ:")
    for method in selected_methods:
        if method in all_results:
            env = all_results[method]['env']
            total_tasks = env.succeeded_tasks + env.rejected_tasks
            if total_tasks > 0:
                success_rate = env.succeeded_tasks / total_tasks * 100
                print(f"   {method:15}: {success_rate:6.2f}% ({env.succeeded_tasks}/{total_tasks})")
    
    # é¡¯ç¤ºæœ€çµ‚episodeçå‹µæ¯”è¼ƒï¼ˆæŒ‰åŸ·è¡Œé †åºï¼‰
    print(f"\nğŸ¯ å„æ–¹æ³•æœ€çµ‚episodeçå‹µæ¯”è¼ƒ:")
    for method in selected_methods:
        if method in all_results:
            final_reward = all_results[method]['rewards'][-1] if all_results[method]['rewards'] else 0
            print(f"   {method:15}: {final_reward:8.2f}")
    
    print(f"\nğŸ‰ å¯¦é©—å®Œæˆï¼")
    if not args.no_save:
        print(f" çµæœä¿å­˜åœ¨: {PATHS['results_path']}")
        print(f" åœ–è¡¨ä¿å­˜åœ¨: {PATHS['plots_path']}")
        print(f" æ¨¡å‹ä¿å­˜åœ¨: {PATHS['save_path']}")
    
    return 0


if __name__ == "__main__":
    exit_code = main()